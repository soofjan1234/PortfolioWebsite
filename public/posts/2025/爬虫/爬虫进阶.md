# 爬虫工程化开发
1. 日志系统：使用 loguru 替代 print，实现分级日志、日志轮转和持久化
2. 配置管理：使用 pydantic-settings 统一管理配置，支持环境变量和 .env 文件
   - 相比 load_dotenv：pydantic-settings 提供类型验证、自动转换、默认值和 IDE 补全
   - 启动时自动校验配置完整性，缺少必填项直接报错，避免运行时问题
3. 异常处理：自定义异常类，使用 tenacity 实现优雅的重试机制
   - 装饰器方式声明重试策略，代码更简洁
   - 内置指数退避、特定异常重试、重试回调等功能，无需手写循环逻辑
4. 推荐目录结构
```
my_crawler/
├── config/                 # 配置模块
│   ├── __init__.py
│   └── settings.py         # 配置定义
├── core/                   # 核心模块
│   ├── __init__.py
│   ├── client.py          # HTTP客户端封装
│   └── retry.py           # 重试策略
├── crawler/               # 爬虫模块
│   ├── __init__.py
│   ├── base.py            # 爬虫基类
│   └── xxx_crawler.py     # 具体爬虫实现
├── parser/                # 解析模块
│   ├── __init__.py
│   └── xxx_parser.py      # 页面解析器
├── store/                 # 存储模块
│   ├── __init__.py
│   ├── base.py            # 存储基类
│   ├── mysql.py           # MySQL存储
│   └── json_store.py      # JSON文件存储
├── models/                # 数据模型
│   ├── __init__.py
│   └── xxx_model.py       # Pydantic模型定义
├── exceptions/            # 异常定义
│   ├── __init__.py
│   └── crawler_exceptions.py
├── utils/                 # 工具函数
│   ├── __init__.py
│   └── helpers.py
├── logs/                  # 日志目录
├── data/                  # 数据输出目录
├── tests/                 # 测试目录
│   └── test_xxx.py
├── .env                   # 环境变量（不提交到git）
├── .env.example           # 环境变量示例
├── .gitignore
├── requirements.txt       # 依赖列表
├── main.py               # 程序入口
└── README.md             # 项目说明
```

# 反爬虫对抗基础：请求伪装

## User-Agent 策略
User-Agent（简称 UA）是 HTTP 请求头中的一个字段，用于标识发起请求的客户端类型\
始终使用同一个 UA容易重复容易封禁，故使用 fake-useragent 库实现 UA 轮换器

## 请求头完整伪装
1. 真实浏览器的请求头是非常丰富的，需构建完整的请求头
2. Referer 表示当前请求是从哪个页面发起的。正确设置 Referer 很重要

## 使用 curl_cffi 模拟浏览器指纹
除了 HTTP 请求头，服务器还可以通过 TLS（HTTPS 握手）的特征来识别客户端。\
不同的客户端在 TLS 握手时会展现不同的特征：支持的加密套件顺序；支持的 TLS 扩展；椭圆曲线参数\
curl_cffi 是一个可以模拟各种浏览器 TLS 指纹的 HTTP 客户端库。

## 速率控制
令牌桶限速器、使用 asyncio.Semaphore 控制并发

## HTTP 错误处理

# 代理IP
1. 代理基础：代理类型、匿名度
   - HTTP代理、HTTPS代理、SOCKS4代理、SOCKS5代理（支持 TCP/UDP，可认证）
   - 透明代理、匿名代理、高匿代理（完全隐藏真实 IP 和代理身份）
2. 代理池设计：获取器、检测器、分配器
   - 统一管理多个代理
   - 自动检测代理有效性
   - 智能分配和轮换代理
   - 记录代理质量评分
3. 爬虫集成：httpx 代理设置、隧道代理
   - 隧道代理是一种特殊的代理模式，你只需连接到固定的代理入口，每次请求自动分配不同的 IP
4. 最佳实践
   - 代理类型：大型网站对代理检测严格，推荐使用高匿住宅代理
   - 请求频率：单IP建议 0.5-1 秒/请求，避免触发频率限制
   - 完整请求头：必须携带 User-Agent、Accept 等头信息
   - Cookie 携带：部分 API 需要登录态，代理请求也要携带 Cookie
   - 失败处理：遇到 403/429 立即切换代理，避免 IP 被永久封禁